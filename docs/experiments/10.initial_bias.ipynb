{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of different initial bias settings for relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from deep_bottleneck.eval_tools.experiment_loader import ExperimentLoader\n",
    "from deep_bottleneck.eval_tools.utils import format_config, find_differing_config_keys\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ExperimentLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = [862, 859, 860, 868, 867, 863, 864, 866, 861, 865, 869, 870]\n",
    "experiments = loader.find_by_ids(experiment_ids)\n",
    "differing_config_keys = find_differing_config_keys(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6,2, figsize=(14, 48))\n",
    "ax = ax.flat\n",
    "\n",
    "for i, experiment in enumerate(experiments):\n",
    "    img = plt.imread(BytesIO(experiment.artifacts['infoplane_test'].content))\n",
    "    ax[i].axis('off')\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_title(format_config(experiment.config, *differing_config_keys),\n",
    "                    fontsize=16)\n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6,2, figsize=(12, 21))\n",
    "ax = ax.flat\n",
    "\n",
    "for i, experiment in enumerate(experiments): \n",
    "    df = pd.DataFrame(data=np.array([experiment.metrics['training.accuracy'].values, \n",
    "                                     experiment.metrics['test.accuracy'].values]).T,\n",
    "                  index=experiment.metrics['test.accuracy'].index,\n",
    "                  columns=['train_acc', 'val_acc'])\n",
    "\n",
    "    df.plot(linestyle='', marker='.', markersize=5, ax=ax[i])\n",
    "    ax[i].set_title(format_config(experiment.config, *differing_config_keys),\n",
    "                    fontsize=12)\n",
    "    ax[i].set_ylim([0,1])\n",
    "    ax[i].set(xlabel='epoch', ylabel='accuracy')\n",
    "\n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6,2, figsize=(14, 48))\n",
    "ax = ax.flat\n",
    "\n",
    "for i, experiment in enumerate(experiments):\n",
    "    img = plt.imread(BytesIO(experiment.artifacts['infoplane_train'].content))\n",
    "    ax[i].axis('off')\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_title(format_config(experiment.config, *differing_config_keys),\n",
    "                    fontsize=16)\n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(12,1, figsize=(14, 48))\n",
    "ax = ax.flat\n",
    "\n",
    "for i, experiment in enumerate(experiments):\n",
    "    img = plt.imread(BytesIO(experiment.artifacts['snr_train'].content))\n",
    "    ax[i].axis('off')\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_title(format_config(experiment.config, *differing_config_keys),\n",
    "                    fontsize=16)\n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(12,1, figsize=(15, 105))\n",
    "ax = ax.flat\n",
    "\n",
    "for i, experiment in enumerate(experiments): \n",
    "    img = plt.imread(BytesIO(experiment.artifacts['activations_train'].content))\n",
    "    ax[i].axis('off')\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_title(format_config(experiment.config, *differing_config_keys),\n",
    "                    fontsize=20)\n",
    "\n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with max_weight_norm=0.4\n",
    "\n",
    "In the following we present an example with `relu` and the norm of the weight vector for each layer restricted to 0.4\n",
    "This is a significantly stronger regularization which this time will also have an effect on the performance of the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu04 = loader.find_by_id(603)\n",
    "relu04.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the infoplane plot below it can be seen that training is impaired for the choice of such strict weight regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu04.artifacts['infoplane'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu04.artifacts['activations'].show(figsize=(12,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation pattern of several peaks is even more pronounced with stronger restiction on the size of the weights. \n",
    "\n",
    "The performance of the network is worse than with higher weightnorm. But the training dynamics still look ok. The network learns the task up to a certain accurcy without overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu04.metrics['training.accuracy'].plot()\n",
    "relu04.metrics['validation.accuracy'].plot()\n",
    "plt.ylabel('accurcy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary material\n",
    "\n",
    "Below we find plots indicating the development of means and standard deviation of the gradient, its signal to noise ratio as well as the norm of the weight vector for all layers over the course of training. Comparing plots for unconstrained vs. constrained weight vector, we can reassure ourselves that rescaling the weights worked as we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,1, figsize=(16, 20))\n",
    "ax = ax.flat\n",
    "\n",
    "for i, experiment in enumerate(experiments): \n",
    "    img = plt.imread(BytesIO(experiment.artifacts['snr'].content))\n",
    "    ax[i].axis('off')\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_title(format_config(experiment.config, *differing_config_keys),\n",
    "                    fontsize=20)\n",
    "\n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we find the configuration of all non-varied parameters that we used for the experiments above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_config_dict = {k: '<var>' for k in differing_config_keys}\n",
    "config = experiment.config\n",
    "config.update(variable_config_dict)\n",
    "config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
